{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "neural-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, length, when, col\n",
    "from pyspark.sql.types import BooleanType, IntegerType, LongType, StringType, ArrayType, FloatType, StructType, StructField\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "from jinja2 import Environment, FileSystemLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chinese-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting constants\n",
    "APP_NAME = \"VVORONIN-SPARK-APP_send\"\n",
    "NORMALIZED_APP_NAME = APP_NAME.replace('/', '_').replace(':', '_')\n",
    "\n",
    "APPS_TMP_DIR = os.path.join(os.getcwd(), \"tmp\")\n",
    "APPS_CONF_DIR = os.path.join(os.getcwd(), \"conf\")\n",
    "APPS_LOGS_DIR = os.path.join(os.getcwd(), \"logs\")\n",
    "LOG4J_PROP_FILE = os.path.join(APPS_CONF_DIR, \"pyspark-log4j-{}.properties\".format(NORMALIZED_APP_NAME))\n",
    "LOG_FILE = os.path.join(APPS_LOGS_DIR, 'pyspark-{}.log'.format(NORMALIZED_APP_NAME))\n",
    "EXTRA_JAVA_OPTIONS = \"-Dlog4j.configuration=file://{} -Dspark.hadoop.dfs.replication=1 -Dhttps.protocols=TLSv1.0,TLSv1.1,TLSv1.2,TLSv1.3\"\\\n",
    "    .format(LOG4J_PROP_FILE)\n",
    "\n",
    "LOCAL_IP = socket.gethostbyname(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "korean-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing configuration files from templates\n",
    "for directory in [APPS_CONF_DIR, APPS_LOGS_DIR, APPS_TMP_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('/opt'))\n",
    "template = env.get_template(\"pyspark_log4j.properties.template\")\n",
    "template\\\n",
    "    .stream(logfile=LOG_FILE)\\\n",
    "    .dump(LOG4J_PROP_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exclusive-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_ADDRESS = \"local[4]\"\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"VVORONIN-SPARK-APP\")\\\n",
    "    .master(SPARK_ADDRESS)\\\n",
    "    .config(\"spark.ui.port\", \"4040\")\\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.6\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .config(\"spark.driver.extraJavaOptions\", EXTRA_JAVA_OPTIONS)\\\n",
    "    .config(\"spark.executor.memory\", \"6g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#для каждого поста получим id его автора\n",
    "posts_data = spark.read.json(\"hdfs:///shared/bigdata20/followers_posts_api_final.json\")\n",
    "posts_df = posts_data.where((col(\"text\") != \"\") & (col(\"text\") != \" \"))\\\n",
    "                .select(col(\"owner_id\").alias(\"user_id\"), \"date\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "#для каждого id получим возраст пользовалетя и пол\n",
    "followers_data = spark.read.json(\"hdfs:///shared/bigdata20/followers_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_df = followers_data.select(col(\"id\").alias(\"user_id\"), \"sex\", \"bdate\")\\\n",
    "                    .withColumn(\"month_between\", \n",
    "                        months_between(current_date(), regexp_extract(col(\"bdate\"), r\"(\\d{1,2})\\.(\\d{1,2})\\.(\\d{4})\", 3).cast(\"date\")))\\\n",
    "                    .select(\"user_id\", \"sex\", (col(\"month_between\")/12).cast(\"int\").alias(\"age\"))\\\n",
    "                    .where(col(\"sex\").isNotNull() & col(\"age\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#соединим одно с другим\n",
    "posts_with_user_info_df = posts_df.join(followers_df, [\"user_id\"])\\\n",
    "                            .select(\"user_id\", col(\"date\"), \"text\", (when(col(\"sex\") == 1, \"M\").otherwise(\"F\")).alias(\"sex\"), \n",
    "                                    \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_with_user_info_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-rainbow",
   "metadata": {},
   "source": [
    "Начинаем передачу данных через kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "#from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=\"kafka-svc:9092\", value_serializer=lambda value: json.dumps(value).encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "focused-titanium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d38033e19869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposts_with_user_info_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoLocalIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"post: {data['user_id']}, date: {data['date']}, sex - {data['sex']}, age - {data['age']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mproducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m# If response is 1 then there is a partition to read, if 0 then fully consumed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sockfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mread_int\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for row in posts_with_user_info_df.rdd.toLocalIterator():\n",
    "    data = row.asDict()\n",
    "    print(f\"post: {data['user_id']}, date: {data['date']}, sex - {data['sex']}, age - {data['age']}\")\n",
    "    \n",
    "    producer.send(\"main\", data)\n",
    "    producer.flush()\n",
    "    time.sleep(random.random())\n",
    "\n",
    "#playsound('~/nfs-home/beep-07a.wav')  \n",
    "print(\"Broadcast has been finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-tomato",
   "metadata": {},
   "source": [
    "# Draft\n",
    "Источник вдохновения. Удаляется без последствий для основной части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'], api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
